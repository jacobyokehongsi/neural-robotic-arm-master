{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3gVctvSRlcV"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GmnXAE2i0YJ",
        "outputId": "f4191d83-538b-4c83-d38b-97a0d2717b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting panda-gym\n",
            "  Downloading panda_gym-3.0.7-py3-none-any.whl (23 kB)\n",
            "Collecting gymnasium>=0.26 (from panda-gym)\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybullet (from panda-gym)\n",
            "  Downloading pybullet-3.2.5.tar.gz (80.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from panda-gym) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from panda-gym) (1.10.1)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium>=0.26->panda-gym)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26->panda-gym) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26->panda-gym) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.26->panda-gym)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Building wheels for collected packages: pybullet\n",
            "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybullet: filename=pybullet-3.2.5-cp310-cp310-linux_x86_64.whl size=101451201 sha256=82a8a778fbc1a7884120ad0680bcec345e69c4739a142139effd21b42669b5e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/fa/1a/c315a5133f0c9bf202a6daa5d70891120e7fe403e06e3407cc\n",
            "Successfully built pybullet\n",
            "Installing collected packages: pybullet, farama-notifications, jax-jumpy, gymnasium, panda-gym\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0 panda-gym-3.0.7 pybullet-3.2.5\n"
          ]
        }
      ],
      "source": [
        "%pip install panda-gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ7gLI7XRsTB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import collections as mc\n",
        "import numpy as np\n",
        "# import sklearn\n",
        "# from sklearn import linear_model\n",
        "import torch\n",
        "\n",
        "# from latent_actions.cvae.vae import VAE\n",
        "# from latent_actions.envs.panda_center_out import PandaCenterOutEnv\n",
        "import pandas as pd\n",
        "torch.manual_seed(0)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "\n",
        "# import torchvision.transforms as transforms\n",
        "# import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from panda_gym.envs.tasks.reach import Reach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSKP4_3cRk1Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from panda_gym.envs.tasks.reach import Reach\n",
        "\n",
        "\n",
        "class CenterOut(Reach):\n",
        "    \"\"\"The center out task is a specific reaching task where the goal is\n",
        "    confined to the level surface of the end effector.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sim,\n",
        "        get_ee_position,\n",
        "        reward_type = \"sparse\",\n",
        "        distance_threshold = 0.05,\n",
        "        goal_range = 0.3,\n",
        "        dimension = 2,\n",
        "    ) -> None:\n",
        "        super().__init__(\n",
        "                sim, get_ee_position, reward_type, distance_threshold,\n",
        "                goal_range)\n",
        "        assert(dimension == 2 or dimension == 3)\n",
        "        self.dimension = dimension\n",
        "\n",
        "    def set_ee_position(self, ee_position: np.ndarray) -> None:\n",
        "        \"\"\"End effector position is the center of the grid.\"\"\"\n",
        "        self.ee_position = ee_position\n",
        "\n",
        "    def _sample_goal(self) -> np.ndarray:\n",
        "        goal_displacement_from_center = np.zeros(self.dimension)\n",
        "        while all(goal_displacement_from_center == 0):\n",
        "            goal_displacement_from_center = self.np_random.choice(\n",
        "                    [self.goal_range_low[0], self.goal_range_high[0], 0],\n",
        "                    self.dimension)\n",
        "\n",
        "        if self.dimension == 2:\n",
        "            goal_displacement_from_center = np.append(\n",
        "                    goal_displacement_from_center, 0)\n",
        "        goal = self.ee_position + goal_displacement_from_center\n",
        "        return goal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKu6DDIpSFuy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from panda_gym.envs.core import RobotTaskEnv\n",
        "from panda_gym.envs.robots.panda import Panda\n",
        "from panda_gym.pybullet import PyBullet\n",
        "\n",
        "# from latent_actions.envs.center_out import CenterOut\n",
        "\n",
        "class PandaCenterOutEnv(RobotTaskEnv):\n",
        "    \"\"\"Reach task wih Panda robot.\n",
        "    Args:\n",
        "        render (bool, optional): Activate rendering. Defaults to False.\n",
        "        reward_type (str, optional): \"sparse\" or \"dense\". Defaults to \"sparse\".\n",
        "        control_type (str, optional): \"ee\" to control end-effector position or \"joints\" to control joint values.\n",
        "            Defaults to \"ee\".\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "            render: bool = False,\n",
        "            reward_type: str = \"sparse\",\n",
        "            control_type: str = \"ee\",\n",
        "            goal_range: int = 0.3,\n",
        "            base: int = [0.0,0.0,0.0],\n",
        "            dimension: int = 2) -> None:\n",
        "        sim = PyBullet()\n",
        "        robot = Panda(\n",
        "                sim, block_gripper=True,\n",
        "                base_position=np.array(base),\n",
        "                control_type=control_type)\n",
        "        robot.reset() # Brings the robot to neutral starting position.\n",
        "        task = CenterOut(\n",
        "                sim, reward_type=reward_type,\n",
        "                get_ee_position=robot.get_ee_position, goal_range=goal_range,\n",
        "                dimension=dimension)\n",
        "        task.set_ee_position(robot.get_ee_position())\n",
        "        super().__init__(robot, task)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL9dvUtWSI4T"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cMjX__ihVhFN"
      },
      "source": [
        "## Simple Cyclic\n",
        "\n",
        "start:tensor([ 0.3350, -0.0200, -0.0700])\n",
        "\n",
        "data categories: joint_angles, actions_joints, ee_positions, ee_velocities\n",
        "\n",
        "usage:\n",
        "train_loader = DataLoader(TensorDataset(ee_velocities, ee_positions), batch_size=128)\n",
        "\n",
        "test_loader = DataLoader(TensorDataset(ee_velocities, ee_positions), batch_size=128)\n",
        "\n",
        "train_data_size = np.array(next(iter(train_loader)))[0].shape\n",
        "\n",
        "train_label_size = np.array(next(iter(train_loader)))[1].shape\n",
        "\n",
        "**function**:\n",
        "\n",
        "train, test = simplecyclicdata(inp='joints', ctxt='ee', batch_size=128)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0KYoW4LuAr-"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "def add_noise(traj, sigma, ratio):\n",
        "    new_traj = copy.deepcopy(traj)\n",
        "    steps_affected = np.random.randint(0, len(new_traj), size=int(len(new_traj)*ratio))\n",
        "    for step in steps_affected:\n",
        "        noise = np.random.normal(0, sigma, 3)\n",
        "        new_traj[step] += noise\n",
        "\n",
        "    return new_traj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRCNf4oQHGDK",
        "outputId": "d9b0a483-3046-4c69-b07c-637b5b70ddc0"
      },
      "outputs": [],
      "source": [
        "def convertdata(dataname: str, actiontype: str, ctxttype: str, noise: bool):\n",
        "  with open(dataname+'_train_data.npy', 'rb') as fp:\n",
        "      train_episodes = np.load(fp)\n",
        "  with open(dataname+'_train_label.npy', 'rb') as fp:\n",
        "      train_labels = np.load(fp)\n",
        "  with open(dataname+'_test_data.npy', 'rb') as fp:\n",
        "      test_episodes = np.load(fp)\n",
        "  with open(dataname+'_test_label.npy', 'rb') as fp:\n",
        "      test_labels = np.load(fp)\n",
        "  env = PandaCenterOutEnv(render=False, control_type='ee',base=[0.0,0.0,0.0])\n",
        "\n",
        "  if noise:                     # ee pos                 # gripper v\n",
        "    # clean this up by creating a function to add noise\n",
        "    mega_test = np.hstack((test_episodes[:,4:], test_labels[:,-1].reshape(-1,1)))\n",
        "    for i in np.arange(10):\n",
        "      test = add_noise(test_episodes[:,4:7], 1e-2, 0.3) # ee positions (3)\n",
        "      test = np.hstack((test, test_episodes[:,-1].reshape(-1,1),  test_labels[:,-1].reshape(-1,1))) # stack with grip v and grip width; results bad if add noise to grip\n",
        "      mega_test = np.vstack((mega_test, test)) # unnoised + noised\n",
        "    test_labels = mega_test.copy()\n",
        "\n",
        "    mega_train = np.hstack( (train_episodes[:,4:],train_labels[:,-1].reshape(-1,1)) )\n",
        "    for i in np.arange(10):\n",
        "      train = add_noise(train_episodes[:,4:7],1e-2,0.3)\n",
        "      train = np.hstack( (train, train_episodes[:,-1].reshape(-1,1),  train_labels[:,-1].reshape(-1,1)) )\n",
        "      mega_train = np.vstack( (mega_train, train) )\n",
        "    train_labels = mega_train.copy()\n",
        "\n",
        "    # inverse kinematics stuff to obtain velocities from positions\n",
        "    joint_angles_test = np.array( [env.robot.inverse_kinematics(link=11, position=ee_pos, orientation=np.array([1.0,0.0,0.0,0.0])) for ee_pos in mega_test[:,:-2]])[:,:7] # -2 to ignore gripper w & v (dont need IK for gripper); first 7 joints from panda gym\n",
        "    actions_joints_test = np.vstack( ( (joint_angles_test[1:] - joint_angles_test[:-1]), np.zeros((1,7)) )) # x1 - x0 / t1 - t0 = velocity\n",
        "    joint_angles_train = np.array( [env.robot.inverse_kinematics(link=11, position=ee_pos, orientation=np.array([1.0,0.0,0.0,0.0])) for ee_pos in mega_train[:,:-2]])[:,:7]\n",
        "    actions_joints_train = np.vstack( ( (joint_angles_train[1:] - joint_angles_train[:-1]), np.zeros((1,7)) ))\n",
        "\n",
        "    if actiontype == 'joints':\n",
        "      train_labels = np.hstack( (actions_joints_train, mega_train[:,-1].reshape(-1,1)))\n",
        "      test_labels = np.hstack( (actions_joints_test, mega_test[:,-1].reshape(-1,1)))\n",
        "      print(train_labels.shape, test_labels.shape)\n",
        "      np.save(dataname+'_train_label_'+'joints'+'.npy', train_labels)\n",
        "      np.save(dataname+'_test_label_'+'joints'+'.npy', test_labels)\n",
        "\n",
        "    if ctxttype == 'joints':\n",
        "      train_episodes = np.hstack( (train_episodes[:,:4], joint_angles_train, train_episodes[:,-1].reshape(-1,1)))\n",
        "      test_episodes = np.hstack( (test_episodes[:,:4], joint_angles_test, test_episodes[:,-1].reshape(-1,1)))\n",
        "      np.save(dataname+'_train_episode_'+'joints'+'.npy', train_episodes)\n",
        "      np.save(dataname+'_test_episode_'+'joints'+'.npy', test_episodes)\n",
        "\n",
        "  else:\n",
        "    joint_angles_test = np.array( [env.robot.inverse_kinematics(link=11, position=ee_pos, orientation=np.array([1.0,0.0,0.0,0.0])) for ee_pos in test_episodes[:,4:7]])[:,:7]\n",
        "    actions_joints_test = np.vstack( ( (joint_angles_test[1:] - joint_angles_test[:-1]), np.zeros((1,7)) ))\n",
        "    joint_angles_train = np.array( [env.robot.inverse_kinematics(link=11, position=ee_pos, orientation=np.array([1.0,0.0,0.0,0.0])) for ee_pos in train_episodes[:,4:7]])[:,:7]\n",
        "    actions_joints_train = np.vstack( ( (joint_angles_train[1:] - joint_angles_train[:-1]), np.zeros((1,7)) ))\n",
        "\n",
        "    if actiontype == 'joints':\n",
        "      train_labels = np.hstack( (actions_joints_train, train_labels[:,-1].reshape(-1,1)))\n",
        "      test_labels = np.hstack( (actions_joints_test, test_labels[:,-1].reshape(-1,1)))\n",
        "      np.save(dataname+'_train_label_'+'joints'+'.npy', train_labels)\n",
        "      np.save(dataname+'_test_label_'+'joints'+'.npy', test_labels)\n",
        "\n",
        "    if ctxttype == 'joints':\n",
        "      train_episodes = np.hstack( (train_episodes[:,:4], joint_angles_train, train_episodes[:,-1].reshape(-1,1)))\n",
        "      test_episodes = np.hstack( (test_episodes[:,:4], joint_angles_test, test_episodes[:,-1].reshape(-1,1)))\n",
        "      np.save(dataname+'_train_episode_'+'joints'+'.npy', train_episodes)\n",
        "      np.save(dataname+'_test_episode_'+'joints'+'.npy', test_episodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convertdata('cyclic_traj_simple', 'joints', 'ee')\n",
        "# convertdata('cyclic_traj_with_grasping', 'joints', 'ee', True)\n",
        "# convertdata('cyclic_traj_with_grasping_noise', 'joints', 'ee')\n",
        "# convertdata('cyclic_traj_multiple_starts', 'joints', 'ee', True) # joint vels conditioned on ee pos context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7QKcslMXOoP"
      },
      "outputs": [],
      "source": [
        "t = np.zeros((2,7))\n",
        "print(t)\n",
        "print(t.reshape(1,-1).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACLQTBsYSPJb"
      },
      "outputs": [],
      "source": [
        "plt.plot(joint_angles[:,0][:10000])\n",
        "joint_angles[:,0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfdGgTMNSRge"
      },
      "outputs": [],
      "source": [
        "plt.plot(joint_angles[:,3][:10000])\n",
        "joint_angles[:,3].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA0exrhhtajT"
      },
      "outputs": [],
      "source": [
        "# # dataset = TensorDataset(joint_velocities_train)\n",
        "# # dataset = joint_velocities\n",
        "# train_loader = DataLoader(TensorDataset(ee_velocities, ee_positions), batch_size=128)\n",
        "# test_loader = DataLoader(TensorDataset(ee_velocities, ee_positions), batch_size=128)\n",
        "# train_data_size = np.array(next(iter(train_loader)))[0].shape\n",
        "# train_label_size = np.array(next(iter(train_loader)))[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkLTtQndy6wM"
      },
      "outputs": [],
      "source": [
        "def simplecyclicdata(inp='joints', ctxt='ee', batch_size=128):\n",
        "  print('simple cyclic')\n",
        "\n",
        "  with open('cyclic_traj_simple_train_data.npy', 'rb') as fp:\n",
        "      train_episodes = np.load(fp)\n",
        "  with open('cyclic_traj_simple_train_label.npy', 'rb') as fp:\n",
        "      train_labels = np.load(fp)\n",
        "  with open('cyclic_traj_simple_test_data.npy', 'rb') as fp:\n",
        "      test_episodes = np.load(fp)\n",
        "  with open('cyclic_traj_simple_test_label.npy', 'rb') as fp:\n",
        "      test_labels = np.load(fp)\n",
        "\n",
        "  env = PandaCenterOutEnv(render=False, control_type='ee')\n",
        "\n",
        "  joint_angles = torch.Tensor( [env.robot.inverse_kinematics(link=11, position=ee_pos, orientation=np.array([1.0,0.0,0.0])) for ee_pos in train_episodes[:,4:7]])[:,:7]\n",
        "  actions_joints = torch.vstack( ( (joint_angles[1:] - joint_angles[:-1]), torch.zeros((1,7)) ))\n",
        "  ee_positions = torch.Tensor(train_episodes[:,4:7])\n",
        "  ee_velocities = torch.Tensor(train_labels[:,:-1])\n",
        "  print(ee_positions.shape, ee_velocities.shape, joint_angles.shape, actions_joints.shape)\n",
        "  print(ee_positions[0])\n",
        "\n",
        "  if inp=='ee':\n",
        "    X = ee_velocities\n",
        "  elif inp=='joints':\n",
        "    X = actions_joints\n",
        "\n",
        "  if ctxt=='ee':\n",
        "    c = ee_positions\n",
        "  elif ctxt=='joints':\n",
        "    c = joint_angles\n",
        "  X = torch.Tensor(X)\n",
        "  y = X\n",
        "\n",
        "  if ctxt=='none':\n",
        "    print('no context')\n",
        "    traind = DataLoader(TensorDataset(X,y), batch_size=batch_size)\n",
        "\n",
        "  else:\n",
        "    c = torch.Tensor(c)\n",
        "    # X = torch.hstack( (X, c))\n",
        "    traind = DataLoader(TensorDataset(X,c), batch_size=batch_size)\n",
        "\n",
        "  testd = traind #fix later\n",
        "  return traind, testd\n",
        "\n",
        "# #uncomment to test\n",
        "# train, test = simplecyclicdata(inp = 'ee', ctxt='none')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGrykQyAV9xU"
      },
      "source": [
        "## cyclic grasp\n",
        "\n",
        "start: tensor([ 0.3350, -0.0200, -0.0700])\n",
        "\n",
        "data categories: joint_angles, actions_joints, ee_positions, ee_velocities\n",
        "\n",
        "usage:\n",
        "train_loader = DataLoader(TensorDataset(ee_velocities, ee_positions), batch_size=128)\n",
        "\n",
        "test_loader = DataLoader(TensorDataset(ee_velocities, ee_positions), batch_size=128)\n",
        "\n",
        "train_data_size = np.array(next(iter(train_loader)))[0].shape\n",
        "\n",
        "train_label_size = np.array(next(iter(train_loader)))[1].shape\n",
        "\n",
        "train, test = graspcyclicdata(inp='joints', ctxt='ee', batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fzgswh9BUitz"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('cyclic_traj_with_grasping_train_data.npy', 'rb') as fp:\n",
        "    train_episodes = np.load(fp)\n",
        "with open('cyclic_traj_with_grasping_train_label.npy', 'rb') as fp:\n",
        "    train_labels = np.load(fp)\n",
        "with open('cyclic_traj_with_grasping_test_data.npy', 'rb') as fp:\n",
        "    test_episodes = np.load(fp)\n",
        "with open('cyclic_traj_with_grasping_test_label.npy', 'rb') as fp:\n",
        "    test_labels = np.load(fp)\n",
        "\n",
        "env = PandaCenterOutEnv(render=False, control_type='ee')\n",
        "\n",
        "joint_angles_train = torch.Tensor( [env.robot.inverse_kinematics(link=11, position=ee_pos, orientation=np.array([1.0,0.0,0.0])) for ee_pos in train_episodes[:,4:7]])[:,:7]\n",
        "joint_velocities_train = torch.vstack( ( (joint_angles_train[1:] - joint_angles_train[:-1]), torch.zeros((1,7)) ))\n",
        "ee_positions_train = torch.Tensor(train_episodes[:,4:7  ])\n",
        "ee_velocities_train = torch.Tensor(train_labels[:,:-1])\n",
        "gripper_positions_train = torch.Tensor( train_episodes[:-1])\n",
        "gripper_velocities_train = torch.Tensor( train_labels[:-1])\n",
        "print(ee_positions_train.shape, ee_velocities_train.shape, joint_angles_train.shape, joint_velocities_train.shape, gripper_positions_train.shape, gripper_velocities_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "joint_angles_test = torch.Tensor( [env.robot.inverse_kinematics(link=11, position=ee_pos, orientation=np.array([1.0,0.0,0.0])) for ee_pos in test_episodes[:,4:7]])[:,:7]\n",
        "joint_velocities_test = torch.vstack( ( (joint_angles_test[1:] - joint_angles_test[:-1]), torch.zeros((1,7)) ))\n",
        "ee_positions_test = torch.Tensor(test_episodes[:,4:7])\n",
        "ee_velocities_test = torch.Tensor(test_labels[:,:-1])\n",
        "gripper_positions_test = torch.Tensor( test_episodes[:-1])\n",
        "gripper_velocities_test = torch.Tensor( test_labels[:-1])\n",
        "print(ee_positions_test.shape, ee_velocities_test.shape, joint_angles_test.shape, joint_velocities_test.shape, gripper_positions_test.shape, gripper_velocities_test.shape)\n",
        "print(ee_positions_train[0], ee_positions_test[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APpogi19tYWo"
      },
      "outputs": [],
      "source": [
        "# dataset = TensorDataset(joint_velocities_train)\n",
        "# dataset = joint_velocities\n",
        "train_loader = DataLoader(TensorDataset(ee_velocities_train, ee_positions_train), batch_size=128)\n",
        "test_loader = DataLoader(TensorDataset(ee_velocities_test, ee_positions_test), batch_size=128)\n",
        "train_data_size = np.array(next(iter(train_loader)))[0].shape\n",
        "train_label_size = np.array(next(iter(train_loader)))[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzZODAR4UPJW"
      },
      "outputs": [],
      "source": [
        "def graspcyclicdata(inp='joints', ctxt='ee', batch_size=128):\n",
        "\n",
        "\n",
        "  with open('cyclic_traj_with_grasping_train_data.npy', 'rb') as fp:\n",
        "      train_episodes = np.load(fp)\n",
        "  with open('cyclic_traj_with_grasping_train_label.npy', 'rb') as fp:\n",
        "      train_labels = np.load(fp)\n",
        "  with open('cyclic_traj_with_grasping_test_data.npy', 'rb') as fp:\n",
        "      test_episodes = np.load(fp)\n",
        "  with open('cyclic_traj_with_grasping_test_label.npy', 'rb') as fp:\n",
        "      test_labels = np.load(fp)\n",
        "\n",
        "  env = PandaCenterOutEnv(render=False, control_type='ee')\n",
        "\n",
        "  joint_angles_train = torch.Tensor( [env.robot.inverse_kinematics(link=11, position=ee_pos, orientation=np.array([1.0,0.0,0.0])) for ee_pos in train_episodes[:,4:7]])[:,:7]\n",
        "  joint_velocities_train = torch.vstack( ( (joint_angles_train[1:] - joint_angles_train[:-1]), torch.zeros((1,7)) ))\n",
        "  ee_positions_train = torch.Tensor(train_episodes[:,4:7  ])\n",
        "  ee_velocities_train = torch.Tensor(train_labels[:,:-1])\n",
        "  gripper_positions_train = torch.Tensor( train_episodes[:-1])\n",
        "  gripper_velocities_train = torch.Tensor( train_labels[:-1])\n",
        "  print(ee_positions_train.shape, ee_velocities_train.shape, joint_angles_train.shape, joint_velocities_train.shape, gripper_positions_train.shape, gripper_velocities_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  joint_angles_test = torch.Tensor( [env.robot.inverse_kinematics(link=11, position=ee_pos, orientation=np.array([1.0,0.0,0.0])) for ee_pos in test_episodes[:,4:7]])[:,:7]\n",
        "  joint_velocities_test = torch.vstack( ( (joint_angles_test[1:] - joint_angles_test[:-1]), torch.zeros((1,7)) ))\n",
        "  ee_positions_test = torch.Tensor(test_episodes[:,4:7])\n",
        "  ee_velocities_test = torch.Tensor(test_labels[:,:-1])\n",
        "  gripper_positions_test = torch.Tensor( test_episodes[:-1])\n",
        "  gripper_velocities_test = torch.Tensor( test_labels[:-1])\n",
        "  print(ee_positions_test.shape, ee_velocities_test.shape, joint_angles_test.shape, joint_velocities_test.shape, gripper_positions_test.shape, gripper_velocities_test.shape)\n",
        "  print(ee_positions_train[0], ee_positions_test[0])\n",
        "\n",
        "\n",
        "  print('grasp cyclic')\n",
        "  if inp=='ee':\n",
        "    Xtrain = ee_velocities_train\n",
        "    Xtest = ee_velocities_test\n",
        "  elif inp=='joints':\n",
        "    Xtrain = joint_velocities_train\n",
        "    Xtest = joint_velocities_test\n",
        "\n",
        "  Xtrain = torch.Tensor(Xtrain)\n",
        "  Xtest = torch.Tensor(Xtest)\n",
        "\n",
        "  ytrain= Xtrain\n",
        "  ytest = Xtest\n",
        "\n",
        "  if ctxt=='none':\n",
        "    print('no context')\n",
        "    traind = DataLoader(TensorDataset(Xtrain,ytrain), batch_size=batch_size)\n",
        "    testd = DataLoader(TensorDataset(Xtrain,ytrain), batch_size=batch_size)\n",
        "\n",
        "  else:\n",
        "    if ctxt=='ee':\n",
        "      ctrain = ee_positions_train\n",
        "      ctest = ee_positions_test\n",
        "\n",
        "    elif ctxt=='joints':\n",
        "      ctrain = joint_angles_train\n",
        "      ctest = joint_angles_test\n",
        "\n",
        "    ctrain = torch.Tensor(ctrain)\n",
        "    ctest = torch.Tensor(ctest)\n",
        "\n",
        "    traind = DataLoader(TensorDataset(Xtrain,ctrain), batch_size=batch_size)\n",
        "    testd = DataLoader(TensorDataset(Xtest,ctest), batch_size=batch_size)\n",
        "\n",
        "  return traind, testd\n",
        "\n",
        "# #uncomment to test\n",
        "# train, test = graspcyclicdata(inp = 'ee', ctxt='ee')\n",
        "# print(next(iter(train))[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ8viiWlTgUd"
      },
      "source": [
        "# device\n",
        "\n",
        "device call: device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbx8NBZRThWG"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  dev = \"cuda:0\"\n",
        "else:\n",
        "  dev = \"cpu\"\n",
        "device = torch.device(dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqHSEULHTnJR"
      },
      "source": [
        "#M O D E L S"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFzf4sMVeMtd"
      },
      "source": [
        "### random fourier feature mapping:\n",
        "https://bmild.github.io/fourfeat/\n",
        "\n",
        "ffmap(inputdata, outputdim, std)\n",
        "\n",
        "output: [ cos(.*data) , sin(.*data) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntTgSO5LeR5b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def ffmap(data, outdim, sigma=1):\n",
        "    mean = torch.zeros((data.shape[1],outdim))\n",
        "    std = torch.ones_like(mean) * sigma\n",
        "    g = torch.normal(mean, std)\n",
        "    # print(g.shape)\n",
        "    out = torch.matmul(data, g)\n",
        "    out = torch.hstack( (torch.cos(2*math.pi*out), torch.sin(2*math.pi*out)) )\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0LB6LfrX_Mt"
      },
      "source": [
        "## VAE_gumbel(temp=0.5, action_dim=3, context_dim=3, dims=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuAd-5dD2NJ_"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  dev = \"cuda:0\"\n",
        "else:\n",
        "  dev = \"cpu\"\n",
        "\n",
        "is_cuda = torch.device(dev)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "if is_cuda:\n",
        "    torch.cuda.manual_seed(0)\n",
        "\n",
        "\n",
        "latent_dim = 1\n",
        "categorical_dim = 4  # one-of-K vector\n",
        "\n",
        "hard = False\n",
        "\n",
        "# log_interval = 10\n",
        "log_interval = 100\n",
        "ANNEAL_RATE = 0.00003\n",
        "temp_min = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACYt5VLGYCbO"
      },
      "outputs": [],
      "source": [
        "def sample_gumbel(shape, eps=1e-7):\n",
        "    U = torch.rand(shape)\n",
        "    if is_cuda:\n",
        "        U = U.cuda()\n",
        "    return -torch.log(-torch.log(U + eps) + eps)\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, temperature):\n",
        "    y = logits + sample_gumbel(logits.size())\n",
        "    return F.softmax(y / temperature, dim=-1)\n",
        "\n",
        "# latent_dim = 1\n",
        "# categorical_dim = 4\n",
        "def gumbel_softmax(logits, temperature, hard=False):\n",
        "    \"\"\"\n",
        "    ST-gumple-softmax\n",
        "    input: [*, n_class]\n",
        "    return: flatten --> [*, n_class] an one-hot vector\n",
        "    \"\"\"\n",
        "    y = gumbel_softmax_sample(logits, temperature)\n",
        "\n",
        "    if not hard:\n",
        "        return y.view(-1, latent_dim * categorical_dim)\n",
        "\n",
        "    shape = y.size()\n",
        "    _, ind = y.max(dim=-1)\n",
        "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
        "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
        "    y_hard = y_hard.view(*shape)\n",
        "    # Set gradients w.r.t. y_hard gradients w.r.t. y\n",
        "    y_hard = (y_hard - y).detach() + y\n",
        "    return y_hard.view(-1, latent_dim * categorical_dim)\n",
        "\n",
        "class VAE_gumbel(nn.Module):\n",
        "    def __init__(self, temp=0.5, action_dim=3, context_dim=3, dims=50):\n",
        "        super(VAE_gumbel, self).__init__()\n",
        "        self.fc1 = nn.Linear(action_dim+context_dim, dims)\n",
        "        self.bn1 = nn.BatchNorm1d(dims)\n",
        "        self.fc2 = nn.Linear(dims, dims)\n",
        "        self.bn2 = nn.BatchNorm1d(dims)\n",
        "        self.fc3 = nn.Linear(dims, latent_dim * categorical_dim)\n",
        "\n",
        "        self.fc4 = nn.Linear(context_dim+(latent_dim * categorical_dim), dims)\n",
        "        self.bn4 = nn.BatchNorm1d(dims)\n",
        "        self.fc5 = nn.Linear(dims, dims)\n",
        "        self.bn5 = nn.BatchNorm1d(dims)\n",
        "\n",
        "        self.fc6 = nn.Linear(dims, action_dim)\n",
        "\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = self.relu(self.bn1(self.fc1(x)))\n",
        "        h2 = self.relu(self.bn2(self.fc2(h1)))\n",
        "        return self.relu(self.fc3(h2))\n",
        "\n",
        "    def decode(self, z, label):\n",
        "        # print(z.shape, label.shape)\n",
        "        h4 = self.relu(self.bn4(self.fc4(torch.hstack( (z,label) ))))\n",
        "        h5 = self.relu(self.bn5(self.fc5(h4)))\n",
        "        return (self.fc6(h5))\n",
        "\n",
        "    def forward(self, x, temp, hard, label):\n",
        "        x = torch.hstack((x,label))\n",
        "        q = self.encode(x.view(-1, x.shape[-1]))\n",
        "        q_y = q.view(q.size(0), latent_dim, categorical_dim)\n",
        "        z = gumbel_softmax(q_y, temp, hard)\n",
        "        return self.decode(z,label), F.softmax(q_y, dim=-1).reshape(*q.size())\n",
        "\n",
        "# VAE_gumbel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68r6UkYgqcvL"
      },
      "source": [
        "# training loop and evals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y2zkp4Z0-9l"
      },
      "source": [
        "### cyclic simple/grasp/etc\n",
        "\n",
        "end [[0.537, -0.02, -0.07],[0.335, -0.19, -0.07]]\n",
        "\n",
        "start [ 3.8439669e-02 -2.1944723e-12  1.9740014e-01] (using env.step)\n",
        "\n",
        "init = np.array([0.335, -0.02, -0.07]) (cyclic trajs)\n",
        "goals = np.array([[0.335, -0.19, -0.07], [0.537, -0.02, -0.07]])\n",
        "\n",
        "dirs = torch.Tensor([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]])\n",
        "dir_names = ['Up', 'Right', 'Down', 'Left']\n",
        "\n",
        "neutral_joint_values = np.array([0.000000, 0.410000, 0.0000000000, -1.850000000, 0.00000000, 2.26000000, 0.7900000000, 0.00000000, 0.00000000])\n",
        "\n",
        " run(lr=5e-3, ANNEAL_RATE=ANNEAL_RATE, temp_min=temp_min, epochs=100):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnV_XNd51F6b"
      },
      "outputs": [],
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def loss_function(recon_x, x, qy, action_dim=3, alpha = 0.001):\n",
        "    # BCE = F.binary_cross_entropy(recon_x, x.vi  ew(-1, 784), size_average=False) / x.shape[0]\n",
        "    # BCE = F.binary_cross_entropy(recon_x, x.view(-1, 10), size_average=False) / x.shape[0]\n",
        "\n",
        "    log_ratio = torch.log(qy * categorical_dim + 1e-7)\n",
        "    KLD = torch.sum(qy * log_ratio, dim=-1).mean() #mean matters here\n",
        "    # print(KLD.shape)\n",
        "    # print( torch.sum(qy * log_ratio, dim=-1),  torch.sum(qy * log_ratio, dim=-1).mean() )\n",
        "    recon = F.mse_loss(recon_x, x.view(-1, action_dim)).mean() #mean here is meaningless\n",
        "    # print(F.mse_loss(recon_x, x.view(-1, action_dim)), F.mse_loss(recon_x, x.view(-1, action_dim)).mean())\n",
        "    h1 = qy * torch.log(qy + 1e-7)\n",
        "    h2 = qy * np.log(1. / categorical_dim + 1e-7)\n",
        "    kl = torch.mean(torch.sum(h1-h2, dim=-1), dim=0)\n",
        "    alpha = 0.001\n",
        "    beta = 1\n",
        "    return (beta * recon) + (alpha * kl)\n",
        "\n",
        "def train(model, epoch, m, lr=5e-3, ANNEAL_RATE=3e-5, temp_min=0.5, kl=0.001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    model.cuda()\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    temp = temperature\n",
        "    # for batch, (X,y) in enumerate(train_loader):\n",
        "      # print(batch, X.shape, y.shape)\n",
        "      # break\n",
        "    for batch_idx, (data, label) in enumerate(train_loader):\n",
        "        if is_cuda:\n",
        "            data = data.cuda()\n",
        "            label = label.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, qy = model(data, temp, hard, label)\n",
        "        loss = loss_function(recon_batch, data, qy, data.shape[-1], kl)\n",
        "        # print(loss.shape, len(data), len(train_loader.dataset))\n",
        "        loss.backward()\n",
        "        train_loss += loss.item() * len(data)\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 1:\n",
        "            temp = np.maximum(temp * np.exp(-ANNEAL_RATE * batch_idx), temp_min)\n",
        "\n",
        "        # if batch_idx % log_interval == 0:\n",
        "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        #                100. * batch_idx / len(train_loader),\n",
        "        #                loss.item()))\n",
        "    if epoch%100 == 0:\n",
        "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "            epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "def test(model, epoch, temp_min=0.5):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    temp = temperature\n",
        "    # for i, (data, label) in enumerate(test_loader):\n",
        "    #     print(data.shape, label.shape, i)\n",
        "    for i, (data, label) in enumerate(test_loader):\n",
        "        if is_cuda:\n",
        "            data = data.cuda()\n",
        "            label = label.cuda()\n",
        "        recon_batch, qy = model(data, temp, hard, label)\n",
        "        test_loss += loss_function(recon_batch, data, qy).item() * len(data)\n",
        "        if i % 100 == 1:\n",
        "            temp = np.maximum(temp * np.exp(-ANNEAL_RATE * i), temp_min)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "\n",
        "# temperature = 1.0\n",
        "temperature = 0.5\n",
        "temp_min = 0.5\n",
        "ANNEAL_RATE = 0.00003\n",
        "\n",
        "# fdsa = VAE_gumbel(temp=temperature, action_dim=train_data_size[-1], context_dim=train_label_size[-1], dims = 50)\n",
        "# if is_cuda:\n",
        "    # fdsa.cuda()\n",
        "# train = 1\n",
        "# test = 1\n",
        "def run(model, lr=5e-3, ANNEAL_RATE=ANNEAL_RATE, temp_min=temp_min, epochs=100, kl = 0.001):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, epoch, lr, ANNEAL_RATE, temp_min, kl)\n",
        "        # test(model, epoch)\n",
        "# train_loader, test_loader = graspcyclicdata(inp = 'ee', ctxt='ee', batch_size=64)\n",
        "\n",
        "# #uncomment to test\n",
        "# run(fdsa, epochs=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "g3gVctvSRlcV",
        "dED4_-disZk8",
        "tSfJmKwwVm9O",
        "CJ8viiWlTgUd",
        "FqHSEULHTnJR",
        "CFzf4sMVeMtd",
        "1JGO43M6WD33",
        "Z9tNQSPeX6tz",
        "iuXAHBHYX5OQ",
        "16bbzRNxlC3D"
      ],
      "gpuClass": "premium",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
